{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450aa759-0612-4b82-82c1-43e7b8c5ef08",
   "metadata": {},
   "source": [
    "# Character Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491d90a-bce1-4ee6-a4bb-d50b969d7eb1",
   "metadata": {},
   "source": [
    "## 0. Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9faf2a6-8d56-4d35-9dab-f4a1881e3039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# helpful character encoding module\n",
    "import charset_normalizer\n",
    "\n",
    "# set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947a1e6-ddf3-49e8-8519-07fc32cbbc70",
   "metadata": {},
   "source": [
    "## 1. What are encodings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d495010-b21f-4771-9c4b-2865cc3b9251",
   "metadata": {},
   "source": [
    "字元編碼是將原始二進制位元組串（看起來像這樣：0110100001101001）映射到構成人類可讀文本（如「hi」）的字元的特定規則集。  \n",
    "有許多不同的編碼，如果你嘗試用與原始書寫不同的編碼來讀取文本，你最終會得到一種叫做「文字亂碼」（發音像 mo-gee-bah-kay）的混亂文本。  \n",
    "以下是文字亂碼的一個例子："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdb566-f08e-43dd-9e16-5602232613fc",
   "metadata": {},
   "source": [
    "æ–‡å—åŒ–ã??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc415df5-8701-4e90-adfe-393fc549c819",
   "metadata": {},
   "source": [
    "你也可能遇到「未知」字符。當某個特定位元組與你用來讀取位元組串的編碼中的字符之間沒有映射時，  \n",
    "就會顯示這些字符，它們看起來像這樣："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa41656-95ce-42cd-b9e9-f1cb20a1c976",
   "metadata": {},
   "source": [
    "����������"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92547f1e-4fa3-4a55-b54f-019d20ccc252",
   "metadata": {},
   "source": [
    "字符編碼不匹配的問題今天比以前少見，但絕對仍然是一個問題。  \n",
    "有許多不同的字符編碼，但你需要知道的主要編碼是 UTF-8。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c0123-05f8-4d4b-b3d0-234e6988049a",
   "metadata": {},
   "source": [
    "**UTF-8 是標準文本編碼。**所有 Python 程式碼都使用 UTF-8，理想情況下，你的所有數據也應該如此。  \n",
    "當事情不使用 UTF-8 時，你就會遇到麻煩。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040847e-c64e-4f89-ad72-711bbe4f6173",
   "metadata": {},
   "source": [
    "在 Python 2 中處理編碼相當困難，但幸運的是在 Python 3 中這變得簡單許多。  \n",
    "（Kaggle 筆記本僅使用 Python 3。）在 Python 3 中處理文本時，你會遇到兩種主要的數據類型。  \n",
    "其中一種是字符串，這是文本的默認類型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd948665-7002-45d4-a5c8-938b5e4c1de1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with a string\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# check to see what datatype it is\n",
    "type(before)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef2f98-5273-4f55-bfd7-9bc0b6a7aeb0",
   "metadata": {},
   "source": [
    "另一種數據類型是位元組數據類型，它是一系列的整數。  \n",
    "你可以通過指定其編碼來將字符串轉換成位元組："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d554369-1194-4563-b301-3661056ce8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "# check the type\n",
    "type(after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8239a-7dc1-4f46-8a6e-06a460abe18e",
   "metadata": {},
   "source": [
    "如果你觀察一個位元組對象，你會看到它前面有一個 b，然後可能在後面有一些文字。  \n",
    "這是因為位元組在打印時，就好像它們是用 ASCII 編碼的字符一樣。  \n",
    "（ASCII 是一種較舊的字符編碼，除了英語之外，實際上不適用於書寫任何其他語言。）在這裡，  \n",
    "你可以看到我們的歐元符號被替換成了一些看起來像 \"\\xe2\\x82\\xac\" 的文字亂碼，  \n",
    "當它被當作 ASCII 字符串打印時就是這樣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4deb5e20-cbec-4de3-baf1-923f893225d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'This is the euro symbol: \\xe2\\x82\\xac'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at what the bytes look like\n",
    "after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fae62a-583f-4fd4-9b49-fde9bd1963f5",
   "metadata": {},
   "source": [
    "當我們使用正確的編碼將我們的位元組再次轉換回字符串時，  \n",
    "我們可以看到我們的文本都正確無誤地顯示出來，這很棒！:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62148719-5d9b-408a-8313-fa4c8c96022b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "# convert it back to utf-8\n",
    "print(after.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f5329-3cda-4a07-9280-8650a99c9468",
   "metadata": {
    "tags": []
   },
   "source": [
    "然而，當我們嘗試使用不同的編碼將我們的位元組映射成字符串時，我們得到了一個錯誤。  \n",
    "這是因為我們試圖使用的編碼不知道該如何處理我們試圖傳遞給它的位元組。  \n",
    "你需要告訴 Python 位元組字符串實際上應該使用的編碼。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b660e-c07b-41cb-b1fd-4ccf696dcf13",
   "metadata": {},
   "source": [
    "**你可以將不同的編碼想像成錄製音樂的不同方式。你可以在 CD、卡帶或 8 軌帶上錄製相同的音樂。  \n",
    "雖然音樂聽起來或多或少是相同的，但你需要使用正確的設備來從每種錄音格式播放音樂。  \n",
    "正確的解碼器就像是卡帶播放器或 CD 播放器。如果你嘗試在 CD 播放器中播放卡帶，它就不會工作。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59bfbc4f-7172-4048-bfa1-e9ce8a3e7a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# try to decode our bytes with the ascii encoding\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mafter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mascii\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# try to decode our bytes with the ascii encoding\n",
    "print(after.decode(\"ascii\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadec94-8b12-4001-8c4e-464420364a2b",
   "metadata": {},
   "source": [
    "如果我們嘗試使用錯誤的編碼從字符串映射到位元組，我們也會遇到問題。  \n",
    "正如我之前所說，Python 3 中的字符串預設是 UTF-8，  \n",
    "所以如果我們嘗試將它們當作另一種編碼處理，我們將會造成問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba0b8cb-39a4-4032-9473-21fd2b7b94d4",
   "metadata": {},
   "source": [
    "例如，如果我們嘗試使用 `encode()` 將字符串轉換為 ASCII 的位元組，我們可以要求位元組是假設文本為 ASCII 時的樣子。  \n",
    "然而，由於我們的文本不是 ASCII，會有一些字符它無法處理。我們可以自動替換 ASCII 無法處理的字符。  \n",
    "但是，如果我們這樣做，任何不在 ASCII 中的字符都將被替換為未知字符。然後，當我們將位元組重新轉換為字符串時，  \n",
    "該字符將被替換為未知字符。這樣做的危險之處在於無法確定它原本應該是什麼字符。  \n",
    "這意味著我們可能剛剛使我們的數據變得無法使用！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77fb006f-2d00-4929-b6de-26564d8ba794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: ?\n"
     ]
    }
   ],
   "source": [
    "# start with a string\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# convert it back to utf-8\n",
    "print(after.decode(\"ascii\"))\n",
    "\n",
    "# We've lost the original underlying byte string! It's been \n",
    "# replaced with the underlying byte string for the unknown character :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576bb29-e1d4-49d8-a2b6-1d2c4b2c33e5",
   "metadata": {},
   "source": [
    "這很糟糕，我們要避免這樣做！最好是盡快將我們所有的文本轉換為 UTF-8，並保持該編碼。  \n",
    "將非 UTF-8 輸入轉換為 UTF-8 的最佳時機是在讀取文件時，我們接下來將會談到這個話題。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6c760-3909-4cc6-8d34-c52802b75aee",
   "metadata": {},
   "source": [
    "## 2. Reading in files with encoding problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea453edc-dcdb-433b-af2c-00b6075d65e6",
   "metadata": {},
   "source": [
    "你遇到的大多數文件可能都是使用 UTF-8 編碼的。  \n",
    "這是 Python 預設期望的，所以大多數時候你不會遇到問題。  \n",
    "然而，有時候你會遇到像這樣的錯誤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f60704-8b74-4c6a-98af-dd71e4196317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# try to read in a file not in UTF-8\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m kickstarter_2016 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mks-projects-201612.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python_conda\\envs\\torch_uni\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python_conda\\envs\\torch_uni\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\Python_conda\\envs\\torch_uni\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python_conda\\envs\\torch_uni\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python_conda\\envs\\torch_uni\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:579\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:668\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:879\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:890\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2050\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x99 in position 7955: invalid start byte"
     ]
    }
   ],
   "source": [
    "# try to read in a file not in UTF-8\n",
    "kickstarter_2016 = pd.read_csv(\"ks-projects-201612.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c423f8-b28e-43a3-be72-1f44db4d1341",
   "metadata": {},
   "source": [
    "請注意，當我們嘗試將 UTF-8 位元組解碼為 ASCII 時，我們得到的 `UnicodeDecodeError` 與此時相同！  \n",
    "這告訴我們這個文件實際上不是 UTF-8。雖然我們不知道它實際上是什麼編碼。  \n",
    "一種弄清楚的方法是嘗試測試一系列不同的字符編碼，看看是否有任何一種能夠工作。  \n",
    "不過，更好的方法是使用 charset_normalizer 模組嘗試自動猜測正確的編碼。  \n",
    "這並不保證百分之百正確，但通常比隨便猜測要快。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bb9f1-835f-4fa0-a5d0-42fde5931ff8",
   "metadata": {},
   "source": [
    "我打算只查看這個文件的前一萬個位元組。這通常足以對編碼作出一個良好的猜測，且比查看整個文件要快得多。  \n",
    "（尤其是對於大文件，這可能非常慢。）只查看文件的第一部分的另一個原因是，我們可以通過查看錯誤訊息看到第一個問題是第 11 個字符。  \n",
    "因此，我們可能只需要查看文件的一小部分就能弄清楚發生了什麼。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1241fa8-8e95-4331-a7cd-7b694856c94a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'utf-8', 'language': 'English', 'confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# look at the first ten thousand bytes to guess the character encoding\n",
    "with open(\"ks-projects-201801.csv\", 'rb') as rawdata:\n",
    "    result = charset_normalizer.detect(rawdata.read(10000))\n",
    "\n",
    "# check what the character encoding might be\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013f2ff-32e5-4948-92e6-d322072aa3b0",
   "metadata": {},
   "source": [
    "因此，charset_normalizer 有 73% 的把握認為正確的編碼是「Windows-1252」。  \n",
    "讓我們看看這是否正確："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29504a29-3c10-4a54-8fe7-44538381a175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ling-Hao Lin\\AppData\\Local\\Temp\\ipykernel_22936\\2942258619.py:2: DtypeWarning: Columns (13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  kickstarter_2016 = pd.read_csv(\"ks-projects-201612.csv\", encoding='Windows-1252')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09 11:36:00</td>\n",
       "      <td>1000</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26 00:20:50</td>\n",
       "      <td>45000</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16 04:24:11</td>\n",
       "      <td>5000</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000011046</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-08-29 01:00:00</td>\n",
       "      <td>19500</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>1283</td>\n",
       "      <td>canceled</td>\n",
       "      <td>14</td>\n",
       "      <td>US</td>\n",
       "      <td>1283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000014025</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-04-01 13:38:27</td>\n",
       "      <td>50000</td>\n",
       "      <td>2016-02-26 13:38:27</td>\n",
       "      <td>52375</td>\n",
       "      <td>successful</td>\n",
       "      <td>224</td>\n",
       "      <td>US</td>\n",
       "      <td>52375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                               name   \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000004038                                     Where is Hank?   \n",
       "2  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "3  1000011046  Community Film Project: The Art of Neighborhoo...   \n",
       "4  1000014025                               Monarch Espresso Bar   \n",
       "\n",
       "        category  main_category  currency             deadline   goal   \\\n",
       "0          Poetry     Publishing       GBP  2015-10-09 11:36:00   1000   \n",
       "1  Narrative Film   Film & Video       USD  2013-02-26 00:20:50  45000   \n",
       "2           Music          Music       USD  2012-04-16 04:24:11   5000   \n",
       "3    Film & Video   Film & Video       USD  2015-08-29 01:00:00  19500   \n",
       "4     Restaurants           Food       USD  2016-04-01 13:38:27  50000   \n",
       "\n",
       "             launched  pledged       state  backers  country  usd pledged   \\\n",
       "0  2015-08-11 12:12:28        0      failed        0       GB            0   \n",
       "1  2013-01-12 00:20:50      220      failed        3       US          220   \n",
       "2  2012-03-17 03:24:11        1      failed        1       US            1   \n",
       "3  2015-07-04 08:35:03     1283    canceled       14       US         1283   \n",
       "4  2016-02-26 13:38:27    52375  successful      224       US        52375   \n",
       "\n",
       "  Unnamed: 13 Unnamed: 14 Unnamed: 15  Unnamed: 16  \n",
       "0         NaN         NaN         NaN          NaN  \n",
       "1         NaN         NaN         NaN          NaN  \n",
       "2         NaN         NaN         NaN          NaN  \n",
       "3         NaN         NaN         NaN          NaN  \n",
       "4         NaN         NaN         NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the file with the encoding detected by charset_normalizer\n",
    "kickstarter_2016 = pd.read_csv(\"ks-projects-201612.csv\", encoding='Windows-1252')\n",
    "\n",
    "# look at the first few lines\n",
    "kickstarter_2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eafb78-8ead-4815-b2a1-176bd99d0f02",
   "metadata": {},
   "source": [
    "是的，看起來 charset_normalizer 是對的！  \n",
    "文件沒有問題地讀入（雖然我們得到了一個關於資料類型的警告），  \n",
    "當我們查看前幾行時，似乎一切正常。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2558d5e-28da-48eb-bc6b-b200a7665ec8",
   "metadata": {},
   "source": [
    "**如果 charset_normalizer 猜測的編碼不正確怎麼辦？**  \n",
    "由於 charset_normalizer 基本上只是一個精緻的猜測器，有時它會猜錯編碼。  \n",
    "你可以嘗試的一件事是查看更多或更少的文件內容，  \n",
    "看看是否能得到不同的結果，然後再嘗試那個結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bed35-4256-4169-a181-88bdfc8fcde9",
   "metadata": {},
   "source": [
    "## 3. Saving your files with UTF-8 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398520ad-d4fb-499f-af02-3311abfa296f",
   "metadata": {},
   "source": [
    "最後，當你費盡心思將你的文件轉換為 UTF-8 之後，你可能會想保持這種方式。  \n",
    "最簡單的方法是將你的文件以 UTF-8 編碼保存。好消息是，由於 UTF-8 是 Python 中的標準編碼，  \n",
    "當你保存一個文件時，它會默認以 UTF-8 的形式保存："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b73e8295-4761-4f1c-8d80-1a9a21ab89b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save our file (will be saved as UTF-8 by default!)\n",
    "# kickstarter_2016.to_csv(\"ks-projects-201801-utf8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172ff80-861b-42d2-b3c9-25824b8da922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
